
## 模型包目录结构

原始模型包目录结构：
```
cos://bucket/train_models/mv-2302330437837096
├── config.json
├── model
│   ├── model.pth
├── model_service.py
└── requirements.txt

```
优化模型包目录结构（优化后的模型保存到模型仓库时，会在优化模型存储路径下生成 m-xxx/mv-xxx 文件夹，并在该文件夹下将原始模型包拷贝并生成新的优化模型文件 model/tiacc.pt）：


```
cos://bucket/train_models/mv-2302330437837096
├── config.json
├── model
│   ├── model.pth
│   ├── tiacc.pt（TI平台模型优化自动生成的优化后的模型）
├── model_service.py
└── requirements.txt
```

-	config.json：模型服务 API 接口的配置文件，须按照下方的规范进行整理；
-	model：存放模型的文件夹目录，该目录可以客户自己指定，但需要确保 model_service.py 可以正确加载；
-	model.pth：原始模型文件，名称可以客户自己指定，但需要确保 model_service.py 可以正确加载；
-	tiacc.pt：优化模型文件，使用 [模型优化](https://cloud.tencent.com/document/product/851/74676) 功能 后会自动生成，如需要使用优化后的模型进行推理和服务部署，需要在 model_service.py 推理脚本里增加对该模型读取 load 的逻辑，可参考 [推理脚本代码示例](https://cloud.tencent.com/document/product/851/74148)；
-	model_service.py：模型推理脚本，须按照 [推理脚本代码示例](https://cloud.tencent.com/document/product/851/74148) 进行整理；
-	requirements.txt：第三方依赖包，如推理脚本有第三方依赖可以放在 requirements.txt 文件内，如没有可直接忽略，容器服务启动前，会利用 pip 安装 requirements.txt 里面的第三方依赖。
-	其他：其他相关依赖文件，如 model_service.py 依赖的 .py 文件，可以自由放置并打包上传
TI 平台也提供了不同模型的模型包示例，请进入 [模型仓库控制台](https://console.cloud.tencent.com/tione/v2/model?tab=models)，单击**下载推理代码模板**进行下载。


## 推理配置文件规范
config.json 配置脚本，可以用来定义服务的 API 调用输入及输出，和推理脚本 model_service.py是配套的，在线推理服务会解析此文件内容，并展示在前端页面，以供用户方便查看；配置文件示例：
```
{
    "apis": [
        {
            "protocol": "http",
            "url": "/v1/models/m:predict",
            "method": "post",
            "request_example": {
                "images": [
                    "<base64>", "<base64>","<base64>"
                ]
            },
            "response_example": {
                "result": {
                    "result_type": "detection",
                    "model_name": "yolov5",
                    "det_objs": [
                        {
                            "det_boxes": [
                                [0,6,300,530],
                                [10,16,200,430]
                            ],
                            "det_labels": [
                                "dog",
                                "cat"
                            ],
                            "det_labels_idx": [
                                16,
                                19
                            ],
                            "det_scores": [
                                0.7526928186416626,
                                0.7328193764612018
                            ]
                        }
                    ]
                }
            }
        }]
}
```
## 推理配置脚本规范
推理脚本和配置文件需在同一目录层级，推理脚本需要实现 tiinfer.Model 类对应的函数，包含 __init__ 初始化、load 模型加载、preprocess 数据预处理、predict 模型推理、postprocess 后处理函数，代码示例参考 [推理脚本代码示例](https://cloud.tencent.com/document/product/851/74148)。
