

## 背景信息
随着 AI 模型规模的扩大及训练数据的增多，用户对模型的迭代效率要求也随之增长，单个 GPU 的算力已无法满足大部分业务场景，使用单机多卡或多机多卡训练已成为趋势。
目前，单机多卡训练场景的参数借助 NVIDIA NVLINK 技术，已获取较好的解决方案。但多机多卡场景对网络通信存在强依赖，网卡厂商提供了高速互联技术 Infiniband 或 RoCE，虽使多机通信效率大幅提升，但成本也大幅增加。如何在25G或50G VPC 普通网络环境下提升分布式训练系统的通信效率，已成为公有云厂商需解决的问题。

## TACO Train 简介
目前业内已具备较多分布式训练的加速技术，例如多级通信、多流通信、梯度融合、压缩通信等。TACO Train 也引入了类似的加速技术。同时，TACO Train 具备自定义用户态协议栈 HARP，该不同于业界其他方案的创新点，有效地解决了 VPC 环境下多机多卡训练中的网络通信问题。

TACO Train 是腾讯云**异构计算团队**基于 IaaS 资源推出的 AI 训练加速引擎，为用户提供开箱即用的 AI 训练套件。TACO Train 背靠**云帆Oteam**，基于腾讯内部丰富的 AI 业务场景，提供自底向上的网络通信、分布式策略及训练框架等多层级的优化，是一套全生态的训练加速方案。

## 训练加速组件
TACO Train 目前提供了三个训练加速组件：
- **Tencent Tensorflow 1.15**：基于 Tensorflow 1.15深度优化的训练框架（以下简称 TTF）。
- **LightCC**：基于 Horovod 深度优化的分布式训练框架。
- **HARP**：自研用户态网络协议栈。                         

详细介绍如下：

<dx-accordion>
::: TTF
TensorFlow 是深度学习领域中应用最广泛的开源框架之一，但在很多业务场景下，开源 Tensorflow 有其特定的限制。为了解决实际业务中遇到的问题，TencentTensorflow（以下简称 TTF）提供了以下能力：

- 相比原始的静态 Embedding，高维稀疏动态 Embedding 帮助用户在不需要重新训练的条件下，动态添加和删除特征，按需使用内存，避免 Hash 冲突，同时保留原始 TF 的 API 设计风格。
- 混合精度在原有实现的基础上增加了调整精度的策略，根据 loss 的状态自动在全精度和半精度之间切换，避免精度损失。
- 针对特定业务场景的 XLA，Grappler 图优化，以及自适应编译框架解决冗余编译的问题。
- 开源 TF 1版本不再提供对 Ampere GPU 的支持，但考虑到较多用户仍在使用 TF 1.15版本的问题，TTF 添加了对 CUDA 11的支持，让用户可以使用 A100来进行模型训练。

:::
::: LightCC

LightCC 是基于 Horovod 深度优化的分布式训练框架，在保留了原生 Horovod 的易用性上，增加了性能更好的通信方式。相比 Horovod，LightCC 提供了以下能力：
- 2D AllReduce 充分利用通信带宽。
- 高效的梯度融合方式。
- TOPK 压缩通信，降低通信量，提高传输效率。


LightCC API 与 Horovod 完全兼容，业务不需要任何改动，无缝迁移。


:::
::: HARP
随着网络硬件技术的发展，网卡的速度从10G增长到100G甚至更高，在数据中心大量部署使用。但目前普遍使用的内核网络协议栈存在着一些必要的开销，使其不能很好地利用高速网络设备。为解决该问题，腾讯云自研了用户态网络协议栈 HARP，可以以 Plug-in 的方式集成到 NCCL 中，无需任何业务改动，加速云上分布式训练性能。在 VPC 的环境下，相比传统的内核协议栈，HARP 提供了以下的能力：

- 支持全链路内存零拷贝，HARP 协议栈提供特定的 buffer 给应用，使应用的数据经过 HARP 协议栈处理后由网卡直接进行收发，消除内核协议栈中耗时及占用 CPU 较高的多次内存拷贝操作。
- 支持协议栈多实例隔离，即应用可以在多个 CPU core 上创建特定协议栈实例处理网络报文，每个实例间相互隔离，保证性能线性增长。
- 数据平面无锁设计，HARP 协议栈内部保证网络 session 的数据仅在创建该 session 的 CPU core 上，使用特定的协议栈实例处理。减少了内核中同步锁的开销，也降低了 CPU 的 Cache Miss 率，大幅提升网络数据的处理性能。



内核协议栈与用户态协议栈 HARP 对比图如下：
![](https://qcloudimg.tencent-cloud.cn/raw/e94f6692167290785fbbbf900c725918.png)  

:::
</dx-accordion>
